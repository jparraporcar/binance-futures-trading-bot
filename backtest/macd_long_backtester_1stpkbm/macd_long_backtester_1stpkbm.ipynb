{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "825bda49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ta\n",
    "import trendet\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import sys\n",
    "sys.path.append('/Users/jp/Desktop/Investment/utils')\n",
    "import utils as utils\n",
    "import math\n",
    "from string import ascii_uppercase\n",
    "from itertools import product\n",
    "import os\n",
    "from binance.client import Client\n",
    "from binance.exceptions import *\n",
    "import requests as requests\n",
    "import time as time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65ede3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Macd_long_backtester_1stpkbm():\n",
    "    \n",
    "    '''\n",
    "    Macd class for backtesting strategies\n",
    "    How to use this class:\n",
    "    1) Use 'prepare_data' method:\n",
    "        INPUTS\n",
    "        - start\n",
    "        - end\n",
    "        - interval\n",
    "        - macd parameters\n",
    "        \n",
    "        COLUMNS CREATED\n",
    "        - macd_diff\n",
    "        - macd_macd\n",
    "        - macd_signal\n",
    "        - log_returns_hold\n",
    "        - multiple_hold_acum\n",
    "        - position\n",
    "        - inv_sign\n",
    "        \n",
    "    In order to perform the backtest first it is necessary to follow 2.1) and 2.2) points in order to get the\n",
    "    period of data of interest. Once this period (start and finish) has been chosen, it is necessary to create\n",
    "    a new instance of the class and follow points 1) and 3)\n",
    "        \n",
    "    2.1) Use 'assign_trends' method: \n",
    "        INPUTS\n",
    "        - window_size\n",
    "        \n",
    "        COLUMNS CREATED\n",
    "        - Up Trend\n",
    "        - Down Trend\n",
    "    \n",
    "    2.2) Use 'get_trend_dates' to obtain the dates 'start' and 'finish' for creating the new instance to perform\n",
    "    the optimization\n",
    "    \n",
    "    3) Use 'execute_backtest' to perform the backtesting analysis for the period obtained, and with the macd\n",
    "    paramters given in the point 1) in the new class instance\n",
    "    \n",
    "    SUMMARY:\n",
    "    \n",
    "    FIRST: points 1) 2.1) and 2.2) --> trends analysis and get period for analysis\n",
    "    SECOND: points 1) and 3) --> new class instance for backtesting with period obtained with get_trend_dates \n",
    "    '''\n",
    "    \n",
    "    def __init__(self,symbol=None):\n",
    "        \n",
    "        \"\"\"Macd long backtester constructor\n",
    "        :param symbol: symbol from Binance from which to extract the data, .i.e. 'BTCUSDT'\n",
    "        :type symbol: str.\n",
    "        :param data: a dataframe with all the data extract from the Binance API for the selected function inputs.\n",
    "        :type data: DataFrame\n",
    "        :param data_uptrend: a dataframe with data extracted from self.data but only for the type of trend\n",
    "        :type data_uptrend: str.\n",
    "        :param data_downtrend: a dataframe with data extracted from self.data but only for the type of trend\n",
    "        :type data_down_trend: str.\n",
    "        :param data_sideways: a dataframe with data extracted from self.data but only for the type of trend\n",
    "        :type data_sideways: str.\n",
    "        \"\"\"\n",
    "        print('class version 1.0 is being used')\n",
    "        self.symbol = symbol\n",
    "        self.data_init = pd.DataFrame()\n",
    "        self.trend_assigned = None\n",
    "        self.interval = None\n",
    "        self.type_trend = None\n",
    "        self.trend_ref = None\n",
    "        #Read-only paramters below, only informative of the last data prepared\n",
    "        self.start = None\n",
    "        self.end = None\n",
    "        self.ema_slow = None\n",
    "        self.ema_fast = None\n",
    "        self.ema_signal = None\n",
    "        self.opt_results = None\n",
    "        self.from_time = None\n",
    "        self.to_time = None\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Macd_long_backtester(symbol={self.symbol})\"\n",
    "\n",
    "    def prepare_data(self, start=None, end=None, interval=None):\n",
    "        '''\n",
    "        REMARK: Introduced time must be in Tokyo time (UTC+9) but the calculations will be in UTC\n",
    "        Prepare all the fields of data necessary for the study. The interval of dates to be studied is the one\n",
    "        given when delclaring the class. To prepare another interval of dates, please create another class instance.\n",
    "        :param start: a string with the following format \"\"%Y-%m-%d-%H:%M\" .i.e. \"2022-01-29-20:00\"\n",
    "        :type start: str.\n",
    "        :param end: a string with the following format \"\"%Y-%m-%d-%H:%M\" .i.e. \"2022-02-29-20:00\"\n",
    "        :type end: str.\n",
    "        :param interval: string among the followings: [\"1m\", \"3m\", \"5m\", \"15m\", \"30m\", \"1h\", \"2h\", \"4h\", \"6h\", \"8h\", \"12h\", \"1d\", \"3d\", \"1w\", \"1M\"]\n",
    "        :type interval: str.\n",
    "        '''\n",
    "\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.interval = interval\n",
    "        from_time = int(datetime.strptime(start, \"%Y-%m-%d-%H:%M\").timestamp()*1000)\n",
    "        to_time = int(datetime.strptime(end, \"%Y-%m-%d-%H:%M\").timestamp()*1000)\n",
    "        self.from_time = from_time\n",
    "        self.to_time = to_time\n",
    "        self.data_init = utils.get_history_v2(symbol=self.symbol, interval=interval, start=from_time, end=to_time)[0]\n",
    "        self.data_init['log_returns_hold'] = np.log(self.data_init.Close.div(self.data_init.Close.shift(1)))\n",
    "        self.data_init['multiple_hold_acum'] = np.exp(self.data_init.log_returns_hold.cumsum())\n",
    "        #initialize positions and sign_inv\n",
    "        self.data_init['position'] = 0\n",
    "        self.data_init['inv_sign'] = 0\n",
    "    \n",
    "    def assign_trends(self, window_size=12, plot=False):\n",
    "        '''\n",
    "        REQUIREMENT: execute after \"prepare_data\" method AND a minimum window size of 12 days\n",
    "        :param window_size: a trend that has a window higher than the introduced number is assigned.\n",
    "        :type window_size: int.\n",
    "        '''\n",
    "        if (window_size < 12):\n",
    "            print('Minimum window size is 12 (calculated with BTCUSDT so far)')\n",
    "            return\n",
    "        \n",
    "        #THE SAMPLING INTERVAL MUST BE DAILY IN ORDER FOR THE ALGORITH TO WORK (AS FAR AS I KNOW)\n",
    "        if (self.interval != '1d'):\n",
    "            print(\"The interval that has to be used to assign trends is '1d'\")\n",
    "            return\n",
    "        \n",
    "        if (self.trend_assigned == True): \n",
    "            print(\"The trends have already been assigned, please execute first 'clean_assign_trend' before executing\\\n",
    "            this method again\")\n",
    "            return\n",
    "        \n",
    "        sns.set(style='darkgrid')\n",
    "        res = trendet.identify_df_trends(df=self.data_init, column='Close', window_size=window_size)\n",
    "        max_close = res.Close.max()      \n",
    "                \n",
    "        plt.figure(figsize=(20, 10))\n",
    "        ax = sns.lineplot(x=res.index, y=res['Close'])\n",
    "        labels = res['Up Trend'].dropna().unique().tolist()\n",
    "\n",
    "        for label in labels:\n",
    "            sns.lineplot(x=res.loc[res['Up Trend'] == label].index, y=res.loc[res['Up Trend'] == label].Close, color='green')\n",
    "            pol1 = ax.axvspan(res.loc[res['Up Trend'] == label].index[0], res.loc[res['Up Trend'] == label].index[-1], alpha=0.2, color='green')\n",
    "            coord = pol1.get_xy()\n",
    "            xcoord = -1 + coord[0][0] + (coord[2][0] - coord[1][0])/2\n",
    "            ax.annotate(label, (xcoord, max_close*3/4))\n",
    "\n",
    "        labels = res['Down Trend'].dropna().unique().tolist()\n",
    "\n",
    "        for label in labels:\n",
    "            sns.lineplot(x=res.loc[res['Down Trend'] == label].index, y=res.loc[res['Down Trend'] == label].Close, color='red')\n",
    "            pol2 =ax.axvspan(res.loc[res['Down Trend'] == label].index[0], res.loc[res['Down Trend'] == label].index[-1], alpha=0.2, color='red')\n",
    "            coord = pol2.get_xy()\n",
    "            xcoord = -1 + coord[0][0] + (coord[2][0] - coord[1][0])/2\n",
    "            ax.annotate(label, (xcoord, max_close*2/4))\n",
    "\n",
    "        increase_letter = False\n",
    "        side_labels = []\n",
    "        i = 0     \n",
    "        \n",
    "        for index, data in res.iterrows():\n",
    "            if (not isinstance(data['Up Trend'], str) and not isinstance(data['Down Trend'], str)):\n",
    "                if (increase_letter == True):\n",
    "                    i+=1\n",
    "                res.loc[index, 'Up Trend'] = ascii_uppercase[i]*2\n",
    "                res.loc[index, 'Down Trend'] = ascii_uppercase[i]*2\n",
    "                side_labels.append(ascii_uppercase[i]*2)\n",
    "                increase_letter = False\n",
    "\n",
    "            if (isinstance(data['Up Trend'], str) or isinstance(data['Down Trend'], str)):\n",
    "                pass\n",
    "                increase_letter = True \n",
    "\n",
    "        for label in side_labels:\n",
    "            sns.lineplot(x=res.loc[res['Up Trend'] == label].index, y=res.loc[res['Up Trend'] == label].Close, color='blue')\n",
    "            pol3 =ax.axvspan(res.loc[res['Up Trend'] == label].index[0], res.loc[res['Up Trend'] == label].index[-1], alpha=0.2, color='grey')\n",
    "            coord = pol3.get_xy()\n",
    "            xcoord = -0.5 + coord[0][0] + (coord[2][0] - coord[1][0])/2\n",
    "            ax.annotate(label, (xcoord, max_close*1/4))\n",
    "\n",
    "        self.trend_assigned = True\n",
    "    \n",
    "    def get_trend_dates(self, type_trend=None, trend_ref=None, do_plot=False):\n",
    "        \n",
    "        '''\n",
    "        REQUIREMENT: execute after \"assign_trends\" method\n",
    "        Once the trends have been assigned in data_init, in this function the type of trend seen in the trends chart\n",
    "        and its trend_ref ('A', 'B', 'AA'...), are given and, as output we receive the start and the end dates of the trend.\n",
    "        :param type: valid fields are 'Up Trend', 'Down Trend' and 'Sideways'\n",
    "        :type type: str.\n",
    "        :param trend_ref: letter/s that have been assigned in the 'Up Trend' and 'Down Trend' columns in data_init\n",
    "        :type type: str.\n",
    "        :param plot: if True, plots the selected trend\n",
    "        :param type: bool.\n",
    "        \n",
    "        :return a tuple with two integers representing the time in milliseconds since the epoch for the start and end period.\n",
    "        '''\n",
    "        \n",
    "        if (type_trend == 'Up Trend'):\n",
    "            date_init = self.data_init.loc[self.data_init['Up Trend'] == trend_ref].index[0]\n",
    "            date_end = self.data_init.loc[self.data_init['Up Trend'] == trend_ref].index[-1]\n",
    "            if (do_plot == True):\n",
    "                mask1 = (self.data_init.index >= date_init) \n",
    "                mask2 = (self.data_init.index <= date_end) \n",
    "                self.data_init.Close[mask1 & mask2].plot(figsize=(15,10))\n",
    "\n",
    "        if (type_trend == 'Down Trend'):\n",
    "            date_init = self.data_init.loc[self.data_init['Down Trend'] == trend_ref].index[0]\n",
    "            date_end = self.data_init.loc[self.data_init['Down Trend'] == trend_ref].index[-1]\n",
    "            if (do_plot == True):\n",
    "                mask1 = (self.data_init.index >= date_init) \n",
    "                mask2 = (self.data_init.index <= date_end) \n",
    "                self.data_init.Close[mask1 & mask2].plot(figsize=(15,10)) \n",
    "                \n",
    "        if (type_trend == 'Sideways'):\n",
    "            #the letters are in both columns so it does not matter which column it is accesed\n",
    "            date_init = self.data_init.loc[self.data_init['Up Trend'] == trend_ref].index[0]\n",
    "            date_end = self.data_init.loc[self.data_init['Up Trend'] == trend_ref].index[-1]\n",
    "            if (do_plot == True):\n",
    "                mask1 = (self.data_init.index >= date_init) \n",
    "                mask2 = (self.data_init.index <= date_end) \n",
    "                self.data_init.Close[mask1 & mask2].plot(figsize=(15,10))            \n",
    "   \n",
    "        date_init_int = int(date_init.timestamp()*1000)\n",
    "        date_end_int = int(date_end.timestamp()*1000)\n",
    "        self.trend_type = type_trend\n",
    "        self.trend_ref = trend_ref\n",
    "       \n",
    "        print('date_init:', date_init, date_init_int)\n",
    "        print('date_end:', date_end, date_end_int)    \n",
    "                                \n",
    "        return (date_init_int, date_end_int)\n",
    "\n",
    "    \n",
    "    def clean_assign_trend(self):\n",
    "        '''Delete the columns 'Up Trend' and 'Down Trend' in data_init generated by the 'assign_trend_method'\n",
    "        '''\n",
    "        if (self.trend_assigned == None):\n",
    "            print('trends must be assigned first')\n",
    "            return\n",
    "        \n",
    "        self.data_init.drop(columns=['Up Trend', 'Down Trend'], inplace=True)\n",
    "        self.trend_assigned = False\n",
    "        \n",
    "    def execute_backtest(self, start=None, ema_slow=None, ema_fast=None, ema_signal=None):\n",
    "        '''\n",
    "        REQUIREMENT: execute after \"prepare_data\" method\n",
    "        :param start: a string with the following format \"\"%Y-%m-%d-%H:%M\" .i.e. \"2022-01-29-20:00\"\n",
    "        :type start: str.\n",
    "        :param end: a string with the following format \"\"%Y-%m-%d-%H:%M\" .i.e. \"2022-02-29-20:00\"\n",
    "        :type end: str.\n",
    "        '''\n",
    "        #Prepare pre-data to start with non NaN at the backtesting period\n",
    "        from_time_obj = datetime.strptime(start, \"%Y-%m-%d-%H:%M\")\n",
    "#       [\"1m\", \"3m\", \"5m\", \"15m\", \"30m\", \"1h\", \"2h\", \"4h\", \"6h\", \"8h\", \"12h\", \"1d\", \"3d\", \"1w\", \"1M\"]\n",
    "        ema_diff = ema_slow + ema_signal + 2\n",
    "        td = timedelta()\n",
    "        if 'm' in self.interval:\n",
    "            num_min = int(self.interval.replace('m',''))\n",
    "            td = timedelta(minutes=num_min*(ema_diff))\n",
    "        if 'h' in self.interval:\n",
    "            num_h = int(self.interval.replace('h',''))\n",
    "            td = timedelta(hours=num_h*(ema_diff))\n",
    "        if 'd' in self.interval:\n",
    "            num_day = int(self.interval.replace('d',''))\n",
    "            td = timedelta(days=num_day*(ema_diff))\n",
    "        if 'w' in self.interval:\n",
    "            num_week = int(self.interval.replace('w',''))\n",
    "            td = timedelta(weeks=num_week*(ema_diff))\n",
    "        if 'M' in self.interval:\n",
    "            num_week_m = int(self.interval.replace('M',''))\n",
    "            td = timedelta(weeks=num_week_m * 4 * (ema_diff))\n",
    "        pre_from_time_obj = from_time_obj - td\n",
    "        pre_from_time = int((from_time_obj - td).timestamp()*1000)\n",
    "        self.data_init_pre = utils.get_history_v2(symbol=self.symbol, interval=self.interval, start=pre_from_time, end=self.to_time)[0]\n",
    "        #Assign the MACD parameters to the class to see which para,tershave been used last\n",
    "        self.ema_slow = ema_slow\n",
    "        self.ema_fast = ema_fast\n",
    "        self.ema_signal = ema_signal \n",
    "        #obtaining MACD instance from python ta\n",
    "        macd_diff = ta.trend.MACD(close=self.data_init_pre.Close, window_slow=ema_slow, window_fast=ema_fast, window_sign=ema_signal, fillna=False).macd_diff()\n",
    "        macd_macd = ta.trend.MACD(close=self.data_init_pre.Close, window_slow=ema_slow, window_fast=ema_fast, window_sign=ema_signal, fillna=False).macd()\n",
    "        macd_signal = ta.trend.MACD(close=self.data_init_pre.Close, window_slow=ema_slow, window_fast=ema_fast, window_sign=ema_signal, fillna=False).macd_signal()\n",
    "        #assigning the values of macd to ticker dataframe\n",
    "        self.data_init_pre['macd_diff'] = macd_diff\n",
    "        self.data_init_pre['macd_macd'] = macd_macd\n",
    "        self.data_init_pre['macd_signal'] = macd_signal   \n",
    "        self.data_init = self.data_init_pre.loc[from_time_obj:].copy()\n",
    "        #Initialize again buy-and-hold parameters for new data\n",
    "        self.data_init['log_returns_hold'] = np.log(self.data_init.Close.div(self.data_init.Close.shift(1)))\n",
    "        self.data_init['multiple_hold_acum'] = np.exp(self.data_init.log_returns_hold.cumsum())\n",
    "        #initialize again positions and sign_inv for new data\n",
    "        self.data_init['position'] = 0\n",
    "        self.data_init['peak'] = 0\n",
    "        \n",
    "        #stablish neutral conditions\n",
    "        cond1 = self.data_init.macd_diff.shift(2) > 0\n",
    "        cond2 = self.data_init.macd_diff.shift(1) > 0\n",
    "        cond3 = self.data_init.macd_diff > 0\n",
    "        cond4 = self.data_init.macd_diff.shift(1) > self.data_init.macd_diff\n",
    "        cond5 = self.data_init.macd_diff.shift(1) > self.data_init.macd_diff.shift(2)\n",
    "        cond_all_neutral = cond1&cond2&cond3&cond4&cond5\n",
    "        #stablish neutral positions\n",
    "        self.data_init.loc[cond_all_neutral, 'peak'] = -1\n",
    "        \n",
    "        #stablish buy conditions\n",
    "        cond6 = self.data_init.macd_diff.shift(2) < 0\n",
    "        cond7 = self.data_init.macd_diff.shift(1) < 0\n",
    "        cond8 = self.data_init.macd_diff < 0\n",
    "        cond9 = self.data_init.macd_diff.shift(1) < self.data_init.macd_diff\n",
    "        cond10 = self.data_init.macd_diff.shift(1) < self.data_init.macd_diff.shift(2)\n",
    "        cond_all_buy = cond6&cond7&cond8&cond9&cond10\n",
    "        #stablish buy positions\n",
    "        self.data_init.loc[cond_all_buy, 'peak'] = 1\n",
    "        #create neutral and buy positions algorithm\n",
    "        buy_peak_repeated= False\n",
    "        sell_peak_repeated = False\n",
    "        for index, data in self.data_init.iterrows():\n",
    "            #neutral conditions\n",
    "            if (data.peak == -1):\n",
    "                if (sell_peak_repeated == True):\n",
    "#                     print('data.peak == -1 && sell_peak_repeated == True branck')\n",
    "#                     print(index, self.data_init.loc[index, 'peak'])\n",
    "                    self.data_init.loc[index, 'peak'] = 0\n",
    "                    buy_peak_repeated = False\n",
    "                    continue\n",
    "                if (sell_peak_repeated == False):\n",
    "#                     print('data.peak == -1 && sell_peak_repeated == False branch')\n",
    "#                     print(index, self.data_init.loc[index, 'peak'])\n",
    "                    sell_peak_repeated = True\n",
    "                    buy_peak_repeated = False #necessary?\n",
    "            if (data.peak == 0):\n",
    "                pass\n",
    "            #buy conditions\n",
    "            if (data.peak == 1):\n",
    "                if (buy_peak_repeated == True):\n",
    "#                     print('data.peak == 1 && buy_peak_repeated == True branch')\n",
    "#                     print(index, self.data_init.loc[index, 'peak'])\n",
    "                    self.data_init.loc[index, 'peak'] = 0\n",
    "                    sell_peak_repeated = False\n",
    "                    continue  \n",
    "                if (buy_peak_repeated == False):\n",
    "#                     print('data.peak == 1 && buy_peak_repeated == False branch')\n",
    "#                     print(index, self.data_init.loc[index, 'peak'])\n",
    "                    buy_peak_repeated = True\n",
    "                    sell_peak_repeated = False\n",
    "                    self.data_init.loc[index, 'position'] = 1\n",
    "                    one_delta_pos = index + (self.data_init.index[1]-self.data_init.index[0])\n",
    "                    self.data_init_sub_buy = self.data_init.loc[one_delta_pos:]\n",
    "                    for index_sub_buy, data_sub_buy in self.data_init_sub_buy.iterrows():\n",
    "                        if (data_sub_buy.peak == 0):\n",
    "                            self.data_init.loc[index_sub_buy, 'position'] = 1\n",
    "                         #if a buy signal is repeated, then go the the proper loop branch   \n",
    "                        if (data_sub_buy.peak == -1):\n",
    "                            break\n",
    "                        if (data_sub_buy.peak == 1):\n",
    "                            self.data_init.loc[index_sub_buy, 'position'] = 1\n",
    "                            self.data_init.loc[index_sub_buy, 'peak'] = 0\n",
    "        #stablish the trading costs and the number of trades done\n",
    "        self.data_init['trades'] = 0\n",
    "        trading_cost = np.log(1 - 0.00075) + np.log(1 - 0.0001)\n",
    "        trade_exec_cond = self.data_init.position.diff().fillna(0).abs() != 0\n",
    "        self.data_init.loc[trade_exec_cond, 'trades'] = 1\n",
    "        #calculate strategy returns\n",
    "        self.data_init['macd_peak_log_returns'] = self.data_init.log_returns_hold * self.data_init.position.shift(2)\n",
    "        self.data_init['macd_peak_log_returns_net'] = self.data_init.macd_peak_log_returns + self.data_init.trades * trading_cost\n",
    "        self.data_init['macd_peak_log_returns_acum'] = np.exp(self.data_init.macd_peak_log_returns.cumsum())\n",
    "        self.data_init['macd_peak_log_returns_net_acum'] = np.exp(self.data_init.macd_peak_log_returns_net.cumsum())\n",
    "\n",
    "        #calculating the function outputs\n",
    "        multiple_hold = np.exp(self.data_init.log_returns_hold.sum())\n",
    "        ann_log_mean_hold = self.data_init.log_returns_hold.mean() * 365\n",
    "        ann_log_std_hold = self.data_init.log_returns_hold.std() * np.sqrt(365)\n",
    "        sharpe_ratio_hold = ann_log_mean_hold / ann_log_std_hold\n",
    "        \n",
    "        multiple_macd_peak_strategy = np.exp(self.data_init.macd_peak_log_returns.sum())\n",
    "        ann_log_mean_macd_peak = self.data_init.macd_peak_log_returns.mean() * 365\n",
    "        ann_log_std_macd_peak = self.data_init.macd_peak_log_returns.std() * np.sqrt(365)\n",
    "        sharpe_ratio_macd_peak = ann_log_mean_macd_peak / ann_log_std_macd_peak\n",
    "        \n",
    "        multiple_macd_peak_strategy_net = np.exp(self.data_init.macd_peak_log_returns_net.sum())\n",
    "        ann_log_mean_macd_peak_net = self.data_init.macd_peak_log_returns_net.mean() * 365\n",
    "        ann_log_std_macd_peak_net = self.data_init.macd_peak_log_returns_net.std() * np.sqrt(365)\n",
    "        sharpe_ratio_macd_peak_net = ann_log_mean_macd_peak_net / ann_log_std_macd_peak_net\n",
    "        \n",
    "        tuple_return = (multiple_hold, ann_log_mean_hold, ann_log_std_hold, sharpe_ratio_hold, multiple_macd_peak_strategy, ann_log_mean_macd_peak, ann_log_std_macd_peak, sharpe_ratio_macd_peak, multiple_macd_peak_strategy_net, ann_log_mean_macd_peak_net, ann_log_std_macd_peak_net, sharpe_ratio_macd_peak_net)\n",
    "\n",
    "        df_return = pd.DataFrame(data=[list(tuple_return)], columns=['multiple_hold', 'ann_log_mean_hold', 'ann_log_std_hold', 'sharpe_ratio_hold', 'multiple_macd_peak_strategy', 'ann_log_mean_macd_peak', 'ann_log_std_macd_peak', 'sharpe_ratio_macd_peak', 'multiple_macd_peak_strategy_net', 'ann_log_mean_macd_peak_net', 'ann_log_std_macd_peak_net', 'sharpe_ratio_macd_peak_net'])\n",
    "        print(df_return)\n",
    "        return tuple_return\n",
    "    \n",
    "    def plot_backtest_results(self, start_plot=None, end_plot=None, width_bars=0.1):\n",
    "        \n",
    "        # from IPython.core.display import display, HTML\n",
    "        # display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "        colors=[]\n",
    "\n",
    "        fig, (close_ax, macd_ax, acum_ax) = plt.subplots(nrows=3, ncols=1, figsize=(30,20), gridspec_kw={'height_ratios': [4,2,4]}, sharex=True)\n",
    "\n",
    "        close_ax.grid(visible=True, which='major', axis='x', color='grey')\n",
    "        macd_ax.grid(visible=True, which='major', axis='x', color='grey')\n",
    "        acum_ax.grid(visible=True, which='major', axis='x', color='grey')\n",
    "        close_ax.grid(visible=True, which='major', axis='y', color='grey')\n",
    "        macd_ax.grid(visible=True, which='major', axis='y', color='grey')\n",
    "        acum_ax.grid(visible=True, which='major', axis='y', color='grey')\n",
    "        close_ax.grid(visible=True, which='minor', axis='x', color='grey')\n",
    "        macd_ax.grid(visible=True, which='minor', axis='x', color='grey')\n",
    "        acum_ax.grid(visible=True, which='minor', axis='x', color='grey')        \n",
    "\n",
    "        close_ax.tick_params(labelrotation=45)\n",
    "        macd_ax.tick_params(labelrotation=45)\n",
    "        acum_ax.tick_params(labelrotation=45)\n",
    "\n",
    "        close_ax.margins(0)\n",
    "        macd_ax.margins(0)\n",
    "        acum_ax.margins(0)\n",
    "        \n",
    "        close_ax.set_ylim(auto=True)\n",
    "\n",
    "#         days = mdates.DayLocator()\n",
    "#         macd_ax.xaxis.set_minor_locator(days)\n",
    "#         date_form = mdates.DateFormatter('%Y-%m-%dT%H:%M:%S')\n",
    "#         close_ax.xaxis.set_major_formatter(date_form)\n",
    "        \n",
    "        data_init_ready = self.data_init              \n",
    "        if ((start_plot != None) and (end_plot !=None)):\n",
    "            cond_start = self.data_init.index >= start_plot\n",
    "            cond_end = self.data_init.index <= end_plot\n",
    "            data_init_ready = self.data_init[cond_start&cond_end]\n",
    "            \n",
    "        for index, value in data_init_ready.macd_diff.iteritems():\n",
    "            if value > 0:\n",
    "                colors.append('g')\n",
    "            else:\n",
    "                colors.append('r')   \n",
    "                \n",
    "        close_ax.plot(data_init_ready.index, data_init_ready.Close) #plot the data without shifting\n",
    "\n",
    "        #shift one position the inv_sign only for plotting the signal in the day after is found, without shifting the\n",
    "        #Close prices\n",
    "        data_init_ready_shift = data_init_ready.copy()\n",
    "        data_init_ready_shift['peak'] = data_init_ready.peak.shift(1)\n",
    "        buy_pos = data_init_ready_shift.peak == 1              \n",
    "        buy_trade = data_init_ready_shift.loc[buy_pos]\n",
    "        sell_pos = data_init_ready_shift.peak == -1             \n",
    "        sell_trade = data_init_ready_shift.loc[sell_pos]\n",
    "        close_ax.scatter(sell_trade.index, sell_trade.Close.loc[sell_trade.index], marker='^', color='r', s=100)\n",
    "        close_ax.scatter(buy_trade.index, buy_trade.Close.loc[buy_trade.index], marker='^', color='g', s=100)\n",
    "        \n",
    "        macd_ax.bar(x= data_init_ready.index, height= data_init_ready.macd_diff, width=width_bars, align='center', color=colors, edgecolor='black')\n",
    "\n",
    "        acum_ax.plot(data_init_ready.index, data_init_ready.multiple_hold_acum)\n",
    "        acum_ax.plot(data_init_ready.index, data_init_ready.macd_peak_log_returns_acum)  \n",
    "        acum_ax.legend(['multiple_hold_acum','macd_peak_log_returns_acum'],fontsize=14)\n",
    "    \n",
    "    def execute_opt(self, start_opt=None, end_opt=None, interval_opt=None, ema_slow_opt=None, ema_fast_opt=None, ema_sign_opt=None, int_for_max=None, type_trend=None, trend_ref=None):\n",
    "        '''\n",
    "        REMARK: Introduced time must be in Tokyo time (UTC+9) but the calculations will be in UTC\n",
    "        '''\n",
    "        interval_opt = interval_opt\n",
    "        macd_slow_opt = range(*ema_slow_opt)\n",
    "        macd_fast_opt = range(*ema_fast_opt)\n",
    "        macd_signal_opt = range(*ema_sign_opt)\n",
    "        combinations = list(product(interval_opt, macd_slow_opt, macd_fast_opt, macd_signal_opt))\n",
    "        \n",
    "        results = []\n",
    "        for comb in combinations:\n",
    "            try:\n",
    "                self.prepare_data(start=start_opt, end=end_opt, interval=comb[0])\n",
    "                tuple_results = (comb[0], comb[1], comb[2], comb[3], *self.execute_backtest(start=self.start, ema_slow=comb[1], ema_fast=comb[2], ema_signal=comb[3]), trend_ref, start_opt, end_opt)\n",
    "                results.append(tuple_results)\n",
    "                print(f\"processed {len(results)} out of a total {len(combinations)}\")\n",
    "            except (BinanceAPIException, ConnectionResetError, requests.exceptions.ConnectionError, requests.exceptions.RequestException) as e:\n",
    "                    print('Something went wrong. Error occured at %s. Wait for 60s.' % (datetime.now().astimezone(timezone.utc)))\n",
    "                    time.sleep(60)\n",
    "                    api_key = \"Q3Zsx6rO7uy0YntyWjb9CTGxbQAfENBxbPAkeOtksXm2AcLcu1y7IOj1fgPFtutO\"\n",
    "                    api_secret = \"LeiOCoJdBuCtfgrt1WfsBweeyC2ZwuogPuDrkXFTioEGoaZYOGkju1GRM3yVqp7v\"\n",
    "                    client = Client(api_key, api_secret)\n",
    "            except KeyboardInterrupt as e2:\n",
    "                    print(\"error type is 'KeyboardInterrupt'. The data calculated so far has been stored in self.opt_results\")\n",
    "                    break\n",
    "        \n",
    "        mg = pd.DataFrame(data=results, columns = ['interval_opt', 'macd_slow_opt', 'macd_fast_opt', 'macd_signal_opt', 'multiple_hold', 'ann_log_mean_hold', 'ann_log_std_hold', 'sharpe_ratio_hold', 'multiple_macd_peak_strategy', 'ann_log_mean_macd_peak', 'ann_log_std_macd_peak', 'sharpe_ratio_macd_peak', 'multiple_macd_peak_strategy_net', 'ann_log_mean_macd_peak_net', 'ann_log_std_macd_peak_net', 'sharpe_ratio_macd_peak_net', 'trend_ref', 'start_opt', 'end_opt'])\n",
    "        #Filtering only meaningfull combinations\n",
    "        cond1 = mg.multiple_macd_peak_strategy != 1 #not enough data to carry out a single crossover\n",
    "        cond2 = mg.macd_slow_opt > mg.macd_fast_opt\n",
    "        mg_filt = mg.loc[cond1&cond2].copy()\n",
    "        self.opt_results = mg_filt.copy()\n",
    "        self.opt_comb_num = len(combinations)\n",
    "        \n",
    "        #only show results for desired interval\n",
    "        cond3 = mg_filt.interval_opt == int_for_max\n",
    "        mg_desired_interval = mg_filt[cond3].copy()\n",
    "        \n",
    "        cond_max = mg_desired_interval.multiple_macd_peak_strategy == mg_desired_interval.multiple_macd_peak_strategy.max()\n",
    "        multiple_macd_peak_strategy_opt_max = mg_desired_interval[cond_max]\n",
    "        \n",
    "        cond_net_max = mg_desired_interval.multiple_macd_peak_strategy_net == mg_desired_interval.multiple_macd_peak_strategy_net.max()\n",
    "        multiple_macd_peak_strategy_net_opt_max = mg_desired_interval[cond_net_max]\n",
    "        \n",
    "        self.multiple_macd_peak_strategy_max = multiple_macd_peak_strategy_opt_max\n",
    "        self.multiple_macd_peak_strategy_net_max = multiple_macd_peak_strategy_net_opt_max\n",
    "\n",
    "        if os.path.exists(f\"{type_trend}.csv\"):\n",
    "            df_imported = pd.read_csv(f\"{type_trend}.csv\")\n",
    "            df_complete = pd.concat([df_imported, self.opt_results], axis = 0)\n",
    "            df_complete.to_csv(f\"{type_trend}.csv\", mode='w', index=False, header=True)\n",
    "        else:\n",
    "            self.opt_results.to_csv(f\"{type_trend}.csv\", mode='w', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
